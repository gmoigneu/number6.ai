---
title: "Why we tell a third of our prospects not to buy AI yet"
subtitle: "The most valuable thing an AI consultant can tell you is 'not yet'"
date: 2025-10-27
author: g
category: honest-take
tags: ["honest take", "ai strategy"]
excerpt: "About a third of the businesses that contact us aren't ready for AI. Telling them that honestly is the best thing we can do for them."
featured_image: "/images/blog/19-why-we-tell-a-third-of-our-prospects-not-to-buy-ai-yet-art.png"
featured_image_alt: "A consultant at a whiteboard with 'not yet' written in large letters"
featured: false
draft: false
---

We'll be honest: this is a strange article for an AI consulting firm to write.

Our business grows when people buy AI. We make money helping companies adopt it. Every prospect we turn away is revenue we're leaving on the table. And yet, roughly a third of the businesses that contact us hear some version of the same thing: "You're not ready for AI yet. Here's what to do first."

This isn't a marketing gimmick. It's not false modesty. And it's not a reverse-psychology sales tactic where we tell you not to buy so you'll want to buy more.

It's a business decision. **Selling AI to a company that isn't ready is the fastest way to create an expensive failure, a resentful client, and a reputation for overpromising.** We've seen other firms do it. The project stumbles. The client blames the technology. The consultant blames the client. Nobody wins.

We'd rather tell you the truth now and earn the right to work with you later.

Here are the three situations where we most often recommend holding off.

## Situation #1: the problem is a process problem, not a technology problem

This is the most common reason we tell prospects to wait, and it surprises people every time.

A business comes to us with a pain point: their customer onboarding takes too long, their reporting is inconsistent, their team spends 20 hours a week on data entry. They've decided AI is the answer. They want us to build something.

So we look at the workflow. And what we find, more often than not, is that the problem isn't a lack of technology. It's a lack of process.

The onboarding takes too long because seven people touch the file and nobody knows who's responsible for what. The reporting is inconsistent because three different teams use three different templates. The data entry takes 20 hours because the same information gets entered into two systems that don't talk to each other.

**Layering AI on top of a broken process doesn't fix the process. It automates the brokenness.** You end up with AI-powered chaos instead of manual chaos. The only difference is you paid $40,000 for the upgrade.

In these cases, we tell the prospect: before you invest in AI, invest in process mapping. Figure out who does what, in what order, and why. Eliminate the redundancies. Standardize the inputs. Then, if there's still a bottleneck that technology can solve, come back and we'll build the right thing.

We've had clients come back six months later after redesigning their processes. Some of them no longer needed AI at all. The process fix solved the problem on its own. Others came back with a much clearer picture of where AI would actually help. Those became some of our best engagements, because we were building on a solid foundation instead of patching over cracks.

### What process problems look like from the outside

They're tricky to identify because they feel like technology problems. Some signals:

The same task takes dramatically different amounts of time depending on who does it. That's not an AI problem. That's a standardization problem.

People are working around the official process because the official process doesn't work. That's not an AI problem. That's a design problem.

There's no single source of truth for important data. Information lives in email threads, spreadsheets, someone's notebook, and a shared drive that nobody can find. AI can't help you search a mess. You need to organize the mess first.

## Situation #2: the team isn't ready

This one's harder to talk about, because it touches on something more sensitive than process design. It touches on people.

AI adoption is a change management challenge as much as a technology challenge. Your team needs to trust the tools, understand how to use them, and be willing to change how they work. If that foundation isn't there, even the best AI implementation will fail.

We've seen the warning signs enough times to recognize them quickly:

**Active resistance.** Key team members have expressed skepticism or opposition to AI. Maybe they're worried about their jobs. Maybe they've been burned by past technology rollouts. Maybe they just don't trust that this time will be different. Whatever the reason, if the people who'll use the tools every day don't want them, the tools won't get used.

**No executive sponsorship.** AI adoption without clear leadership support dies a slow death. Someone with authority needs to champion the change, allocate time for training, and make it clear that adoption matters. "We bought this tool, figure it out" is not executive sponsorship.

**Change fatigue.** The team just went through a CRM migration, a new project management system, or a restructuring. They're exhausted. Dropping another big change on them right now, no matter how beneficial, will meet resistance that has nothing to do with AI and everything to do with timing.

In these situations, I find myself saying the same thing: **the best AI investment you can make right now isn't a tool. It's preparation.** Address the concerns. Build buy-in. Run a few small experiments that let people experience AI without the pressure of a formal rollout. Create curiosity instead of anxiety.

A team that's excited about AI will adopt tools twice as fast and find uses you never anticipated. A team that's been forced into AI adoption will find ways to work around it.

We'd rather wait six months and work with an engaged team than start tomorrow and fight an uphill battle for a year.

### How to build readiness without buying anything

Run an "AI curiosity session." No vendor demos. No commitment. Gather the team and spend an hour playing with a general-purpose AI tool on low-stakes tasks. Let people ask questions. Let skeptics voice their concerns. Make it safe to be uncertain.

Share specific examples of how AI helps people in roles similar to theirs. Not "AI will change everything" headlines. Specific examples: "A team like ours used AI to cut their weekly reporting time in half. Here's what that looked like."

Address the job security question directly. People are worried about this. Ignoring it doesn't make the worry go away. Talk about what AI will and won't change about their roles. Be specific and honest.

These steps cost nothing and they build the foundation that makes actual AI adoption work.

## Situation #3: the data isn't there

AI is only as good as the information it works with. For many AI applications, especially the ones that excite business owners most (customer insights, predictive analytics, automated decision-making), you need organized, accessible, reasonably clean data.

A lot of businesses don't have this. Not because they've been doing anything wrong, but because data organization was never a priority. When you're running a 40-person company, keeping the data tidy isn't usually at the top of the list.

Common data problems we see:

**Scattered information.** Customer data lives in the CRM. Project data lives in spreadsheets. Financial data lives in the accounting software. Employee knowledge lives in people's heads. None of these systems talk to each other, and nobody has a complete picture.

**Inconsistent formats.** The same customer is "Acme Corp" in one system, "ACME Corporation" in another, and "Acme" in a third. Dates are in different formats. Categories overlap and contradict. This sounds minor, but it makes AI tools stumble constantly.

**No historical baseline.** The business wants AI to predict trends or identify patterns, but there's only six months of clean data. Most predictive AI needs years of consistent data to work well. Without it, the predictions are unreliable.

**Tribal knowledge.** The most valuable information in the company exists only in the heads of long-tenured employees. There's no documentation, no knowledge base, no written processes. AI can't learn what was never recorded.

When we see these problems, we don't pretend that buying an AI tool will solve them. We tell the prospect: **spend the next three to six months getting your data house in order.** Consolidate your systems where possible. Standardize your formats. Start documenting the knowledge that lives in people's heads.

Is that as exciting as launching an AI-powered dashboard? No. Is it the work that makes the AI-powered dashboard actually useful when you do build it? Absolutely.

## Why saying "not yet" is good for everyone

From a pure revenue standpoint, turning away a third of our prospects is painful. Every conversation that ends with "not yet" is a project we could have sold. A contract we could have signed. Revenue we chose not to earn.

But here's what happens instead.

**Trust compounds.** When we tell a business they're not ready, something shifts. They stop seeing us as salespeople and start seeing us as advisors. They may not buy today, but when they are ready, they come back. And they bring referrals. "These are the people who told us not to buy when we weren't ready" is the most powerful endorsement we've ever received.

**Projects succeed.** The engagements we do take on have a dramatically higher success rate because we've filtered for readiness. We're not fighting broken processes, resistant teams, or missing data while trying to implement AI. We're building on solid ground. That means better results, happier clients, and case studies we're proud to share.

**Our reputation stays clean.** The AI consulting space is full of firms that'll sell you anything. The bar for differentiation is low: be honest about what works. Every time we tell a prospect the truth, even when it costs us money, it reinforces the thing we're trying to build.

I genuinely believe this is the right approach for a consulting firm our size. We can't afford to have unhappy clients. We can't afford a reputation for overpromising. We can't afford to spend three months on a project that was doomed from the start because the fundamentals weren't there. **Saying "not yet" protects our clients and our business at the same time.**

## What "not yet" actually means

It doesn't mean never. It doesn't mean your business can't benefit from AI. It means the timing isn't right, and there's specific work to do before AI becomes a smart investment.

When we tell a prospect "not yet," we don't just leave them hanging. We tell them exactly what needs to change. Fix this process. Build this foundation. Get your team to this level of readiness. Then let's talk.

Some prospects take that advice and come back in three months, ready to go. Some take it and realize they don't need us at all, because the process fix solved their problem. Some take it and go to another consultant who tells them what they want to hear. That's their call. We won't compete by telling people their problems are bigger than they are.

The best business relationships start with honesty. And sometimes the most honest thing an AI consultant can say is: not yet. But soon. And when you're ready, it'll be worth the wait.
