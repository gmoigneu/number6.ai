---
title: "AI predictions for 2027: what we're confident about and what we're guessing"
subtitle: "Some of these are backed by experience. Some are educated guesses. We'll tell you which is which."
date: 2025-12-11
author: g
category: honest-take
tags: ["honest take", "trends"]
excerpt: "Our AI predictions for 2027, honestly labeled by confidence level. Some we'd bet money on. Others are informed speculation."
featured_image: "/images/blog/30-ai-predictions-for-2027-art.png"
featured_image_alt: "A notebook with handwritten notes and question marks, representing predictions and uncertainty"
featured: false
draft: false
---

Prediction pieces are usually terrible. Someone writes ten confident-sounding forecasts, gets two right, and then writes a follow-up a year later claiming they "called it." Nobody goes back to check the eight they got wrong.

We're going to try something different. We're labeling every prediction with our actual confidence level. Not because we're humble (we have opinions), but because honesty about uncertainty is more useful than false certainty.

Three tiers. **Strong conviction** means we've seen enough from client work and market patterns to bet real money. **Informed position** means we have good reasons but thinner evidence. **Speculation** means we're extrapolating, and we know it.

## Strong conviction: we'd bet money on these

### AI literacy training will become a standard business expense

This is the one we feel most strongly about. Right now, most companies treat AI training as optional. They buy tools, skip the training, wonder why adoption stalls.

By the end of 2027, we think AI literacy training will be as normal as cybersecurity training or onboarding. Not because companies suddenly get enlightened, but because the ones who skip it will fall measurably behind. The productivity gap between a trained team and an untrained one is already obvious in 2026. By 2027, it'll be impossible to ignore.

The US Department of Labor's AI Literacy Framework, published in late 2024, is an early signal. When government agencies start publishing workforce frameworks for a skill, that skill is about to become standard. We've seen this before with digital literacy and cybersecurity awareness.

Every client engagement we've done in the past year has reinforced the same thing. Training is the bottleneck. Not tools, not data, not budget. That pattern is too consistent to be coincidental.

### Most SMBs will routinely use 5 to 10 AI tools

We're already seeing this with clients further along in adoption. One tool for writing and drafting. Another for meeting transcription. A third for data analysis. Maybe one for image generation, one for customer support, one embedded in their CRM.

By 2027, the average small or mid-sized business that takes AI seriously will have 5 to 10 AI tools in regular use. This won't feel revolutionary. It'll feel like how email felt in the early 2000s: gradual, then normal.

The interesting question isn't whether this happens. It's how companies manage it. Tool sprawl is real. Overlapping subscriptions, inconsistent data handling, no central oversight of what the team is actually using. The companies that do this well will have a simple inventory and some basic governance. The ones that don't will waste money and create security gaps they don't even know about.

The tool ecosystem is maturing fast, prices keep dropping, and integrations are getting easier. The friction that kept small businesses from adopting multiple AI tools in 2024 is disappearing.

### The "AI strategy" consulting industry will consolidate

Right now, anyone with a LinkedIn profile and a ChatGPT subscription can call themselves an AI consultant. The barrier to entry is zero, and the market is flooded with solo practitioners and small firms of wildly varying quality.

This won't last. By 2027, we expect significant consolidation. Some consultancies will merge. Many solo practitioners will either build real practices or exit. Clients will get more sophisticated about evaluating consultants, and the ones who can't show measurable outcomes (hours saved, costs reduced, actual adoption rates) will struggle.

This is the normal lifecycle for any consulting niche built around a new technology. It happened with cloud computing. It happened with cybersecurity. The pattern is always the same: gold rush, then consolidation, then professionalization. AI consulting is still in the gold rush. We're biased here (we're an AI consultancy ourselves), but we think consolidation is next.

## Informed position: strong reasons, thinner evidence

### Agent-based workflows will mature into practical business tools

AI agents, software that takes multi-step actions rather than just answering questions, are the biggest area of AI development right now. In 2026, they're mostly experimental. They work in demos. They're unreliable in production.

We think 2027 is when this shifts. Not because agents will become perfect (they won't), but because the infrastructure around them will get good enough. Better error handling. More reliable memory across sessions. Standardized ways to connect agents to business tools.

The practical version will look boring compared to the demos. An agent that takes a customer inquiry, looks up their account, checks inventory, drafts a response, and flags anything unusual for a human. That's not science fiction. That's a customer service workflow with AI handling the repetitive parts.

We're less sure about the timing here. Agent reliability in production is still a real problem. The gap between demo and deployment is wide. We've seen promising pilots, but "promising" and "production-ready" are different things. The pieces are coming together. Whether they come together by December 2027 or take another year, we honestly can't say.

### AI governance will become a B2B buying criterion

We think more businesses will start asking their vendors about AI governance: how they use AI, what data goes into AI tools, what oversight exists.

This won't happen because of some abstract ethical awakening. It'll happen because of the EU AI Act, because of high-profile AI failures that make the news, and because insurance companies and legal teams will start asking questions that trickle down to procurement departments.

For SMBs, this means having answers ready. Not a 50-page policy document. A clear, honest description of how you use AI, what safeguards you have, and who's responsible.

The timeline is fuzzy, though. Regulatory pressure is building but enforcement is slow. Financial services and healthcare will move faster than other industries. Whether governance becomes a mainstream buying criterion by late 2027 or slips into 2028 depends on things we can't predict, like how fast regulators actually move and whether a major AI-related incident changes public perception.

## Speculation: we're extrapolating, and we know it

### What happens if AI costs drop 90%

This is the wildcard. AI model costs have been falling fast. If the trend continues (and there are good reasons to think it will), using AI could become so cheap that the economics change completely.

Right now, cost is a real factor in deployment decisions. A 50-person company running AI on every customer interaction has to think about API costs, per-seat licensing, compute expenses. If those costs drop by 90%, AI stops being something you deploy carefully on high-value tasks and becomes something you run on everything, all the time.

That would reshape which businesses benefit most. Right now, larger companies get more ROI because they spread the fixed costs. If AI becomes nearly free, even a five-person company could afford to augment every workflow.

I genuinely don't know whether this happens in 2027 or takes longer. The trend is real. The pace is uncertain. But it's worth thinking about, because a 90% cost reduction doesn't just make current use cases cheaper. It makes entirely new ones possible.

### The "do we even need that role?" conversation will get louder

I want to be careful with this one because it gets distorted easily. We're not predicting mass layoffs. We don't think AI replaces most jobs.

What we do think is that by 2027, more companies will be asking whether certain roles need to exist in their current form. Not "should we fire the marketing coordinator?" More like "do we need three people doing this if AI handles the repetitive 60%? Could two people do it better with AI support, and the third take on work that's been neglected?"

This conversation is already happening quietly. By 2027, it'll be happening openly. How companies handle it, whether they use AI to make people more effective or just to cut headcount, will determine whether AI adoption builds trust or destroys it within their organizations.

We have anecdotal evidence from client conversations but no hard data on this. The macroeconomic picture matters enormously, and we can't predict that. In a tight labor market, companies use AI to do more with the same team. In a downturn, the same technology becomes a headcount reduction tool. Same technology, very different outcomes.

## What we'll get wrong

Some of these predictions will be wrong. We don't know which ones. That's the nature of predictions, and anyone who tells you otherwise is selling something.

What we can promise is that we'll come back to this piece in February 2028 and grade ourselves honestly. The right calls and the wrong ones. No retroactive editing, no quiet deletions, no reframing misses as partial hits.

If you want to hold us to it, bookmark this page. We'll be here.
